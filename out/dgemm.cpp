
void dgemm (const double* A, const double* B, double* C, double alpha, double beta, const double* prefetch) {{
  __asm__ __volatile__(
    "ldr x0, %0\n\t"
    "ldr x1, %1\n\t"
    "ldr x2, %2\n\t"
    "ldr x3, %3\n\t"
    "ldr x4, %4\n\t"
    "dup v0.2d, x3\n\t"
    "dup v1.2d, x4\n\t"
          // unrolled_8x8x8
        // Broadcast alpha and beta so that efficient multiplication is possible
        // No register based scaling
        // for x12 <- 0:1:1)
        "mov x12, #0\r\n"
        "LOOP_TOP_0_%=:\r\n"
          // Unrolling over bn and bk
            // No register based scaling
            // Load C register block @ (d=0,r=0)
            "ldp q16, q17, [x2, 0]\r\n"                                 // C [0,0] [0,0]
            "ldp q18, q19, [x2, 32]\r\n"                                // C [0,0] [4,0]
            "ldp q20, q21, [x2, 64]\r\n"                                // C [0,0] [0,1]
            "ldp q22, q23, [x2, 96]\r\n"                                // C [0,0] [4,1]
            "ldp q24, q25, [x2, 128]\r\n"                               // C [0,0] [0,2]
            "ldp q26, q27, [x2, 160]\r\n"                               // C [0,0] [4,2]
            "ldp q28, q29, [x2, 192]\r\n"                               // C [0,0] [0,3]
            "ldp q30, q31, [x2, 224]\r\n"                               // C [0,0] [4,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=0)
              "ldp q2, q3, [x0, 0]\r\n"                                   // A [0,0] [0,0]
              "ldp q4, q5, [x0, 32]\r\n"                                  // A [0,0] [4,0]
            "ldr q6, [x1, 0]\r\n"                                       // B[0,0][0,0]
            "ldr q7, [x1, 64]\r\n"                                      // B[0,0][0,1]
            "ldr q8, [x1, 128]\r\n"                                     // B[0,0][0,2]
            "ldr q9, [x1, 192]\r\n"                                     // B[0,0][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[0,0][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[0,0][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[0,0][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[0,0][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[0,0][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[0,0][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[0,0][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[0,0][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[0,0][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[0,0][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[0,0][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[0,0][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[0,0][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[0,0][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[0,0][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[0,0][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=1)
              "ldp q2, q3, [x0, 64]\r\n"                                  // A [0,1] [0,0]
              "ldp q4, q5, [x0, 96]\r\n"                                  // A [0,1] [4,0]
            "ldr q6, [x1, 8]\r\n"                                       // B[1,0][0,0]
            "ldr q7, [x1, 72]\r\n"                                      // B[1,0][0,1]
            "ldr q8, [x1, 136]\r\n"                                     // B[1,0][0,2]
            "ldr q9, [x1, 200]\r\n"                                     // B[1,0][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[1,0][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[1,0][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[1,0][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[1,0][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[1,0][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[1,0][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[1,0][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[1,0][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[1,0][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[1,0][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[1,0][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[1,0][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[1,0][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[1,0][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[1,0][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[1,0][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=2)
              "ldp q2, q3, [x0, 128]\r\n"                                 // A [0,2] [0,0]
              "ldp q4, q5, [x0, 160]\r\n"                                 // A [0,2] [4,0]
            "ldr q6, [x1, 16]\r\n"                                      // B[2,0][0,0]
            "ldr q7, [x1, 80]\r\n"                                      // B[2,0][0,1]
            "ldr q8, [x1, 144]\r\n"                                     // B[2,0][0,2]
            "ldr q9, [x1, 208]\r\n"                                     // B[2,0][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[2,0][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[2,0][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[2,0][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[2,0][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[2,0][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[2,0][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[2,0][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[2,0][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[2,0][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[2,0][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[2,0][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[2,0][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[2,0][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[2,0][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[2,0][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[2,0][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=3)
              "ldp q2, q3, [x0, 192]\r\n"                                 // A [0,3] [0,0]
              "ldp q4, q5, [x0, 224]\r\n"                                 // A [0,3] [4,0]
            "ldr q6, [x1, 24]\r\n"                                      // B[3,0][0,0]
            "ldr q7, [x1, 88]\r\n"                                      // B[3,0][0,1]
            "ldr q8, [x1, 152]\r\n"                                     // B[3,0][0,2]
            "ldr q9, [x1, 216]\r\n"                                     // B[3,0][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[3,0][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[3,0][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[3,0][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[3,0][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[3,0][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[3,0][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[3,0][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[3,0][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[3,0][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[3,0][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[3,0][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[3,0][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[3,0][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[3,0][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[3,0][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[3,0][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=4)
              "add x11, x0, #256\r\n"                                     // 
              "ldp q2, q3, [x11, 0]\r\n"                                  // A [0,4] [0,0]
              "ldp q4, q5, [x11, 32]\r\n"                                 // A [0,4] [4,0]
            "ldr q6, [x1, 32]\r\n"                                      // B[4,0][0,0]
            "ldr q7, [x1, 96]\r\n"                                      // B[4,0][0,1]
            "ldr q8, [x1, 160]\r\n"                                     // B[4,0][0,2]
            "ldr q9, [x1, 224]\r\n"                                     // B[4,0][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[4,0][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[4,0][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[4,0][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[4,0][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[4,0][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[4,0][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[4,0][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[4,0][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[4,0][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[4,0][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[4,0][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[4,0][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[4,0][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[4,0][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[4,0][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[4,0][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=5)
              "add x11, x0, #320\r\n"                                     // 
              "ldp q2, q3, [x11, 0]\r\n"                                  // A [0,5] [0,0]
              "ldp q4, q5, [x11, 32]\r\n"                                 // A [0,5] [4,0]
            "ldr q6, [x1, 40]\r\n"                                      // B[5,0][0,0]
            "ldr q7, [x1, 104]\r\n"                                     // B[5,0][0,1]
            "ldr q8, [x1, 168]\r\n"                                     // B[5,0][0,2]
            "ldr q9, [x1, 232]\r\n"                                     // B[5,0][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[5,0][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[5,0][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[5,0][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[5,0][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[5,0][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[5,0][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[5,0][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[5,0][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[5,0][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[5,0][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[5,0][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[5,0][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[5,0][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[5,0][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[5,0][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[5,0][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=6)
              "add x11, x0, #384\r\n"                                     // 
              "ldp q2, q3, [x11, 0]\r\n"                                  // A [0,6] [0,0]
              "ldp q4, q5, [x11, 32]\r\n"                                 // A [0,6] [4,0]
            "ldr q6, [x1, 48]\r\n"                                      // B[6,0][0,0]
            "ldr q7, [x1, 112]\r\n"                                     // B[6,0][0,1]
            "ldr q8, [x1, 176]\r\n"                                     // B[6,0][0,2]
            "ldr q9, [x1, 240]\r\n"                                     // B[6,0][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[6,0][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[6,0][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[6,0][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[6,0][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[6,0][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[6,0][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[6,0][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[6,0][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[6,0][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[6,0][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[6,0][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[6,0][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[6,0][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[6,0][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[6,0][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[6,0][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=7)
              "add x11, x0, #448\r\n"                                     // 
              "ldp q2, q3, [x11, 0]\r\n"                                  // A [0,7] [0,0]
              "ldp q4, q5, [x11, 32]\r\n"                                 // A [0,7] [4,0]
            "ldr q6, [x1, 56]\r\n"                                      // B[7,0][0,0]
            "ldr q7, [x1, 120]\r\n"                                     // B[7,0][0,1]
            "ldr q8, [x1, 184]\r\n"                                     // B[7,0][0,2]
            "ldr q9, [x1, 248]\r\n"                                     // B[7,0][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[7,0][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[7,0][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[7,0][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[7,0][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[7,0][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[7,0][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[7,0][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[7,0][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[7,0][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[7,0][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[7,0][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[7,0][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[7,0][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[7,0][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[7,0][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[7,0][0,3]
            // Store C register block @ (d=0,r=0)
            "stp q16, q17, [x2, 0]\r\n"                                 // C [0,0] [0,0]
            "stp q18, q19, [x2, 32]\r\n"                                // C [0,0] [4,0]
            "stp q20, q21, [x2, 64]\r\n"                                // C [0,0] [0,1]
            "stp q22, q23, [x2, 96]\r\n"                                // C [0,0] [4,1]
            "stp q24, q25, [x2, 128]\r\n"                               // C [0,0] [0,2]
            "stp q26, q27, [x2, 160]\r\n"                               // C [0,0] [4,2]
            "stp q28, q29, [x2, 192]\r\n"                               // C [0,0] [0,3]
            "stp q30, q31, [x2, 224]\r\n"                               // C [0,0] [4,3]
          "add x2, x2, #256\r\n"                                      // Move C to (d=0,r=1)
            // Load C register block @ (d=0,r=0)
            "ldp q16, q17, [x2, 0]\r\n"                                 // C [0,0] [0,0]
            "ldp q18, q19, [x2, 32]\r\n"                                // C [0,0] [4,0]
            "ldp q20, q21, [x2, 64]\r\n"                                // C [0,0] [0,1]
            "ldp q22, q23, [x2, 96]\r\n"                                // C [0,0] [4,1]
            "ldp q24, q25, [x2, 128]\r\n"                               // C [0,0] [0,2]
            "ldp q26, q27, [x2, 160]\r\n"                               // C [0,0] [4,2]
            "ldp q28, q29, [x2, 192]\r\n"                               // C [0,0] [0,3]
            "ldp q30, q31, [x2, 224]\r\n"                               // C [0,0] [4,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=0)
              "ldp q2, q3, [x0, 0]\r\n"                                   // A [0,0] [0,0]
              "ldp q4, q5, [x0, 32]\r\n"                                  // A [0,0] [4,0]
            "add x11, x1, #256\r\n"                                     // 
            "ldr q6, [x11, 0]\r\n"                                      // B[0,1][0,0]
            "ldr q7, [x11, 64]\r\n"                                     // B[0,1][0,1]
            "ldr q8, [x11, 128]\r\n"                                    // B[0,1][0,2]
            "ldr q9, [x11, 192]\r\n"                                    // B[0,1][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[0,1][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[0,1][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[0,1][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[0,1][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[0,1][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[0,1][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[0,1][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[0,1][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[0,1][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[0,1][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[0,1][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[0,1][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[0,1][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[0,1][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[0,1][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[0,1][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=1)
              "ldp q2, q3, [x0, 64]\r\n"                                  // A [0,1] [0,0]
              "ldp q4, q5, [x0, 96]\r\n"                                  // A [0,1] [4,0]
            "add x11, x1, #264\r\n"                                     // 
            "ldr q6, [x11, 0]\r\n"                                      // B[1,1][0,0]
            "ldr q7, [x11, 64]\r\n"                                     // B[1,1][0,1]
            "ldr q8, [x11, 128]\r\n"                                    // B[1,1][0,2]
            "ldr q9, [x11, 192]\r\n"                                    // B[1,1][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[1,1][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[1,1][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[1,1][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[1,1][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[1,1][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[1,1][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[1,1][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[1,1][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[1,1][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[1,1][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[1,1][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[1,1][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[1,1][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[1,1][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[1,1][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[1,1][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=2)
              "ldp q2, q3, [x0, 128]\r\n"                                 // A [0,2] [0,0]
              "ldp q4, q5, [x0, 160]\r\n"                                 // A [0,2] [4,0]
            "add x11, x1, #272\r\n"                                     // 
            "ldr q6, [x11, 0]\r\n"                                      // B[2,1][0,0]
            "ldr q7, [x11, 64]\r\n"                                     // B[2,1][0,1]
            "ldr q8, [x11, 128]\r\n"                                    // B[2,1][0,2]
            "ldr q9, [x11, 192]\r\n"                                    // B[2,1][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[2,1][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[2,1][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[2,1][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[2,1][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[2,1][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[2,1][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[2,1][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[2,1][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[2,1][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[2,1][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[2,1][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[2,1][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[2,1][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[2,1][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[2,1][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[2,1][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=3)
              "ldp q2, q3, [x0, 192]\r\n"                                 // A [0,3] [0,0]
              "ldp q4, q5, [x0, 224]\r\n"                                 // A [0,3] [4,0]
            "add x11, x1, #280\r\n"                                     // 
            "ldr q6, [x11, 0]\r\n"                                      // B[3,1][0,0]
            "ldr q7, [x11, 64]\r\n"                                     // B[3,1][0,1]
            "ldr q8, [x11, 128]\r\n"                                    // B[3,1][0,2]
            "ldr q9, [x11, 192]\r\n"                                    // B[3,1][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[3,1][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[3,1][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[3,1][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[3,1][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[3,1][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[3,1][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[3,1][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[3,1][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[3,1][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[3,1][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[3,1][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[3,1][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[3,1][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[3,1][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[3,1][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[3,1][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=4)
              "add x11, x0, #256\r\n"                                     // 
              "ldp q2, q3, [x11, 0]\r\n"                                  // A [0,4] [0,0]
              "ldp q4, q5, [x11, 32]\r\n"                                 // A [0,4] [4,0]
            "add x11, x1, #288\r\n"                                     // 
            "ldr q6, [x11, 0]\r\n"                                      // B[4,1][0,0]
            "ldr q7, [x11, 64]\r\n"                                     // B[4,1][0,1]
            "ldr q8, [x11, 128]\r\n"                                    // B[4,1][0,2]
            "ldr q9, [x11, 192]\r\n"                                    // B[4,1][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[4,1][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[4,1][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[4,1][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[4,1][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[4,1][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[4,1][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[4,1][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[4,1][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[4,1][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[4,1][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[4,1][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[4,1][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[4,1][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[4,1][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[4,1][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[4,1][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=5)
              "add x11, x0, #320\r\n"                                     // 
              "ldp q2, q3, [x11, 0]\r\n"                                  // A [0,5] [0,0]
              "ldp q4, q5, [x11, 32]\r\n"                                 // A [0,5] [4,0]
            "add x11, x1, #296\r\n"                                     // 
            "ldr q6, [x11, 0]\r\n"                                      // B[5,1][0,0]
            "ldr q7, [x11, 64]\r\n"                                     // B[5,1][0,1]
            "ldr q8, [x11, 128]\r\n"                                    // B[5,1][0,2]
            "ldr q9, [x11, 192]\r\n"                                    // B[5,1][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[5,1][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[5,1][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[5,1][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[5,1][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[5,1][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[5,1][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[5,1][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[5,1][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[5,1][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[5,1][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[5,1][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[5,1][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[5,1][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[5,1][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[5,1][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[5,1][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=6)
              "add x11, x0, #384\r\n"                                     // 
              "ldp q2, q3, [x11, 0]\r\n"                                  // A [0,6] [0,0]
              "ldp q4, q5, [x11, 32]\r\n"                                 // A [0,6] [4,0]
            "add x11, x1, #304\r\n"                                     // 
            "ldr q6, [x11, 0]\r\n"                                      // B[6,1][0,0]
            "ldr q7, [x11, 64]\r\n"                                     // B[6,1][0,1]
            "ldr q8, [x11, 128]\r\n"                                    // B[6,1][0,2]
            "ldr q9, [x11, 192]\r\n"                                    // B[6,1][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[6,1][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[6,1][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[6,1][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[6,1][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[6,1][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[6,1][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[6,1][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[6,1][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[6,1][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[6,1][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[6,1][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[6,1][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[6,1][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[6,1][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[6,1][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[6,1][0,3]
            // Block GEMM microkernel
              // Load A register block @ (d=0,r=7)
              "add x11, x0, #448\r\n"                                     // 
              "ldp q2, q3, [x11, 0]\r\n"                                  // A [0,7] [0,0]
              "ldp q4, q5, [x11, 32]\r\n"                                 // A [0,7] [4,0]
            "add x11, x1, #312\r\n"                                     // 
            "ldr q6, [x11, 0]\r\n"                                      // B[7,1][0,0]
            "ldr q7, [x11, 64]\r\n"                                     // B[7,1][0,1]
            "ldr q8, [x11, 128]\r\n"                                    // B[7,1][0,2]
            "ldr q9, [x11, 192]\r\n"                                    // B[7,1][0,3]
            "fmla v16.2d, v2.2d, v6.2d[0]\r\n"                          // C[0:2,0] += A[0:2,0]*B[7,1][0,0]
            "fmla v20.2d, v2.2d, v7.2d[0]\r\n"                          // C[0:2,1] += A[0:2,0]*B[7,1][0,1]
            "fmla v24.2d, v2.2d, v8.2d[0]\r\n"                          // C[0:2,2] += A[0:2,0]*B[7,1][0,2]
            "fmla v28.2d, v2.2d, v9.2d[0]\r\n"                          // C[0:2,3] += A[0:2,0]*B[7,1][0,3]
            "fmla v17.2d, v3.2d, v6.2d[0]\r\n"                          // C[2:4,0] += A[2:4,0]*B[7,1][0,0]
            "fmla v21.2d, v3.2d, v7.2d[0]\r\n"                          // C[2:4,1] += A[2:4,0]*B[7,1][0,1]
            "fmla v25.2d, v3.2d, v8.2d[0]\r\n"                          // C[2:4,2] += A[2:4,0]*B[7,1][0,2]
            "fmla v29.2d, v3.2d, v9.2d[0]\r\n"                          // C[2:4,3] += A[2:4,0]*B[7,1][0,3]
            "fmla v18.2d, v4.2d, v6.2d[0]\r\n"                          // C[4:6,0] += A[4:6,0]*B[7,1][0,0]
            "fmla v22.2d, v4.2d, v7.2d[0]\r\n"                          // C[4:6,1] += A[4:6,0]*B[7,1][0,1]
            "fmla v26.2d, v4.2d, v8.2d[0]\r\n"                          // C[4:6,2] += A[4:6,0]*B[7,1][0,2]
            "fmla v30.2d, v4.2d, v9.2d[0]\r\n"                          // C[4:6,3] += A[4:6,0]*B[7,1][0,3]
            "fmla v19.2d, v5.2d, v6.2d[0]\r\n"                          // C[6:8,0] += A[6:8,0]*B[7,1][0,0]
            "fmla v23.2d, v5.2d, v7.2d[0]\r\n"                          // C[6:8,1] += A[6:8,0]*B[7,1][0,1]
            "fmla v27.2d, v5.2d, v8.2d[0]\r\n"                          // C[6:8,2] += A[6:8,0]*B[7,1][0,2]
            "fmla v31.2d, v5.2d, v9.2d[0]\r\n"                          // C[6:8,3] += A[6:8,0]*B[7,1][0,3]
            // Store C register block @ (d=0,r=0)
            "stp q16, q17, [x2, 0]\r\n"                                 // C [0,0] [0,0]
            "stp q18, q19, [x2, 32]\r\n"                                // C [0,0] [4,0]
            "stp q20, q21, [x2, 64]\r\n"                                // C [0,0] [0,1]
            "stp q22, q23, [x2, 96]\r\n"                                // C [0,0] [4,1]
            "stp q24, q25, [x2, 128]\r\n"                               // C [0,0] [0,2]
            "stp q26, q27, [x2, 160]\r\n"                               // C [0,0] [4,2]
            "stp q28, q29, [x2, 192]\r\n"                               // C [0,0] [0,3]
            "stp q30, q31, [x2, 224]\r\n"                               // C [0,0] [4,3]
        "add x0, x0, #64\r\n"                                       // Move A to (d=1,r=0)
        "add x2, x2, #-192\r\n"                                     // Move C to (d=1,r=-1)
        "add x12, x12, #1\r\n"
        "cmp x12, #1\r\n"
        "b.lo LOOP_TOP_0_%=\r\n"

    : : "m"(A), "m"(B), "m"(C), "m"(alpha), "m"(beta) : "r0","r1","r11","r12","r2","v16","v17","v18","v19","v2","v20","v21","v22","v23","v24","v25","v26","v27","v28","v29","v30","v31","v4","v6","v7","v8","v9");
    
    #ifndef NDEBUG
    #ifdef _OPENMP
    #pragma omp atomic
    #endif
    pspamm_num_total_flops += {flop};
    #endif

}};